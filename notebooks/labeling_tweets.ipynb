{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catagorizing the tweets using pre-trained language models\n",
    "\n",
    "It is highly recommend to run this notebook with GPU acceleration\n",
    "(For example, using Google Colab). Running on CPU may take several days, whereas running on a GPU takes approximately 3-6 hours.\n",
    "\n",
    "I recommend creating a seperate virtual environment since we will need many\n",
    "one-off dependencies. Or again, use Google Colab\n",
    "\n",
    "When using free Colab, it is strongly recommended to download the file 'tweets_with_analysis' after each\n",
    "analaysis run, since free Colab doesn't support long idle times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_gpu = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the following packages: (uncomment and run to install)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "# !pip install -q datasets\n",
    "# !pip install sentencepiece\n",
    "# !pip install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not on Colab you will need to install the following packages as well: (uncomment and run to install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch\n",
    "#!pip3 install protobuf==3.20.0\n",
    "#!pip install pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "kwargs_dict = {'device': 0} if run_on_gpu else dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('../datasets/twitter/somalia_tweets.csv')\n",
    "# For testing purposes, we only run with the first 50 observations!\n",
    "# Remove this line for replication purposes\n",
    "df_tweets = df_tweets.head(50)\n",
    "dataset = Dataset.from_pandas(df_tweets[['text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analaysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "task = pipeline(\"sentiment-analysis\", model=model_path,\n",
    "                tokenizer=model_path, max_length=512, truncation=True, **kwargs_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_labels = []\n",
    "for out in tqdm(task(KeyDataset(dataset, \"text\"))):\n",
    "    sentiment_labels.append(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = pd.DataFrame(sentiment_labels)\n",
    "sentiment_labels.columns = 'sentiment_' + sentiment_labels.columns\n",
    "\n",
    "df_final = pd.concat([df_tweets, sentiment_labels], axis=1)\n",
    "df_final.to_csv('../datasets/twitter/tweets_with_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catagorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/tweet-topic-21-multi\"\n",
    "task = pipeline(\"text-classification\", model=model_path,\n",
    "                tokenizer=model_path, max_length=512, truncation=True, **kwargs_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "source": [
    "category_labels = []\n",
    "for out in tqdm(task(KeyDataset(dataset, \"text\"))):\n",
    "    category_labels.append(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = pd.DataFrame(category_labels)\n",
    "category_labels.columns = 'category_' + sentiment_labels.columns\n",
    "\n",
    "df_final = pd.concat([df_final, category_labels], axis=1)\n",
    "df_final.to_csv('../datasets/twitter/tweets_with_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 873/873 [00:00<00:00, 434kB/s]\n",
      "Downloading: 100%|██████████| 515M/515M [00:48<00:00, 11.0MB/s] \n",
      "Downloading: 100%|██████████| 318/318 [00:00<00:00, 159kB/s]\n",
      "Downloading: 100%|██████████| 824k/824k [00:00<00:00, 1.75MB/s]\n",
      "Downloading: 100%|██████████| 1.03M/1.03M [00:00<00:00, 1.62MB/s]\n",
      "Downloading: 100%|██████████| 17.0/17.0 [00:00<00:00, 1.42kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"cardiffnlp/bertweet-base-emotion\"\n",
    "task = pipeline(\"text-classification\", model=model_path,\n",
    "                tokenizer=model_path, max_length=128, truncation=True, **kwargs_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "source": [
    "emotion_labels = []\n",
    "for out in tqdm(task(KeyDataset(dataset, \"text\"))):\n",
    "    emotion_labels.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = pd.DataFrame(emotion_labels)\n",
    "emotion_labels.columns = 'emotion_' + emotion_labels.columns\n",
    "emotion_labels['emotion_label'] = emotion_labels['emotion_label'].replace({'LABEL_0': 'anger', 'LABEL_1': 'joy', 'LABEL_2': 'optimism', 'LABEL_3': 'sadness'})\n",
    "df_final = pd.concat([df_tweets, emotion_labels], axis=1)\n",
    "df_final.to_csv('../datasets/twitter/tweets_with_analysis.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a36d43513a0c594ef50631855dc064693dac3722a6429bb1ee70e59be59af33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
