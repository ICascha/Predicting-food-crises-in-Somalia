{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_ndvi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model \n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "o0hrD7Q0XPpT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fJevVQm1XMAL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    '/content/world_bank_processed.csv', parse_dates=['date'])\n",
        "df.set_index(['area', 'date'], inplace=True)\n",
        "df = df['ndvi_mean']\n",
        "df = (df - df.mean())/df.std()\n",
        "df.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnj7j5oEf1Xr",
        "outputId": "e36ff21a-1ebb-42d8-a10d-078301a1fd57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for year in [2017, 2018]:\n",
        "    dir = f'/content/drive/MyDrive/encodings/{year}_new_encoded/'\n",
        "    for district in listdir(dir):\n",
        "        name = district[:-4]\n",
        "        data = np.load(dir + district)\n",
        "        n_patches = data.shape[0]\n",
        "        \n",
        "        df_temp = df.loc[name]\n",
        "        mask = (df_temp.index < pd.to_datetime(f'{year+1}-01-01')) & (df_temp.index >= pd.to_datetime(f'{year}-01-01'))\n",
        "        labels = np.repeat(df_temp[mask].to_numpy(), n_patches).reshape(12, n_patches).T\n",
        "        data = data.reshape(-1, 16, 16, 64)\n",
        "        labels = labels.reshape(-1)\n",
        "        \n",
        "        X.append(data)\n",
        "        y.append(labels)\n",
        "\n",
        "X = np.concatenate(X, axis=0)\n",
        "y = np.concatenate(y, axis=0)"
      ],
      "metadata": {
        "id": "uRSSsVX3Xbfl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = []\n",
        "y_val = []\n",
        "year = 2019\n",
        "\n",
        "dir = f'/content/drive/MyDrive/encodings/{year}_new_encoded/'\n",
        "for district in listdir(dir):\n",
        "    name = district[:-4]\n",
        "    data = np.load(dir + district)\n",
        "    n_patches = data.shape[0]\n",
        "    \n",
        "    df_temp = df.loc[name]\n",
        "    mask = (df_temp.index < pd.to_datetime(f'{year+1}-01-01')) & (df_temp.index >= pd.to_datetime(f'{year}-01-01'))\n",
        "    labels = np.repeat(df_temp[mask].to_numpy(), n_patches).reshape(12, n_patches).T\n",
        "    data = data.reshape(-1, 16, 16, 64)\n",
        "    labels = labels.reshape(-1)\n",
        "    \n",
        "    X_val.append(data)\n",
        "    y_val.append(labels)\n",
        "\n",
        "X_val = np.concatenate(X_val, axis=0)\n",
        "y_val = np.concatenate(y_val, axis=0)"
      ],
      "metadata": {
        "id": "xZPcYdyVXiHW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(x, n_filters_in, n_filters_out, n_convs=1, activation=\"relu\", batchNorm=False):\n",
        "    x_in = x\n",
        "    for _ in range(n_convs):\n",
        "        x = layers.Conv2D(n_filters_in, (3, 3), activation=activation, padding=\"same\")(x)\n",
        "        #x = layers.Dropout(.8)(x)\n",
        "        if batchNorm:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    if x_in.shape[-1] != x.shape[-1]:\n",
        "            x_in = layers.Conv2D(n_filters_in, (1, 1), padding=\"same\")(x_in)\n",
        "    x = layers.Add()([x, x_in])\n",
        "\n",
        "    y = layers.Conv2D(n_filters_out, (3, 3), strides=2, activation=activation, padding=\"same\")(x)\n",
        "    if batchNorm:\n",
        "            y = layers.BatchNormalization()(y)\n",
        "    x = layers.Conv2D(n_filters_out, (1, 1), strides=2, padding=\"same\")(x)\n",
        "    x_out = layers.Add()([y, x])\n",
        "    return x_out"
      ],
      "metadata": {
        "id": "8YUHCa9KXigs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=(16, 16, 64))\n",
        "x = encoder_block(input, 256, 256, n_convs=2, batchNorm=True)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(25, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(25, activation=\"relu\")(x)\n",
        "x = layers.Dense(1)(x)\n",
        "model = Model(input, x)\n",
        "model.compile(optimizer=Adam(learning_rate=5e-5), loss=\"mse\")"
      ],
      "metadata": {
        "id": "OIk7TacBXkPm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQZLNOLyfGok",
        "outputId": "ef5aec94-70c0-4072-a2d4-c9b311c90b2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 16, 16, 64)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 256)  147712      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 256)  590080      ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 256)  16640       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 256)    590080      ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 8, 256)    65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 16384)        0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 25)           409625      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25)          100         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 25)           650         ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            26          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,823,777\n",
            "Trainable params: 1,822,191\n",
            "Non-trainable params: 1,586\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X, y=y, epochs=20, batch_size=64, shuffle=True, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9_0qldMX4Cp",
        "outputId": "16c332d7-b14c-4765-da98-ddb2bf135115"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "330/330 [==============================] - 9s 22ms/step - loss: 0.3232 - val_loss: 0.2600\n",
            "Epoch 2/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.1404 - val_loss: 0.2222\n",
            "Epoch 3/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.1024 - val_loss: 0.2053\n",
            "Epoch 4/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0794 - val_loss: 0.2036\n",
            "Epoch 5/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0685 - val_loss: 0.1927\n",
            "Epoch 6/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0581 - val_loss: 0.2149\n",
            "Epoch 7/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0536 - val_loss: 0.1768\n",
            "Epoch 8/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0494 - val_loss: 0.1982\n",
            "Epoch 9/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0458 - val_loss: 0.1766\n",
            "Epoch 10/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0410 - val_loss: 0.2267\n",
            "Epoch 11/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0402 - val_loss: 0.1966\n",
            "Epoch 12/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0369 - val_loss: 0.2066\n",
            "Epoch 13/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0352 - val_loss: 0.1615\n",
            "Epoch 14/20\n",
            "330/330 [==============================] - 7s 20ms/step - loss: 0.0354 - val_loss: 0.1623\n",
            "Epoch 15/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0331 - val_loss: 0.1507\n",
            "Epoch 16/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0317 - val_loss: 0.1728\n",
            "Epoch 17/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0301 - val_loss: 0.1750\n",
            "Epoch 18/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0284 - val_loss: 0.1936\n",
            "Epoch 19/20\n",
            "330/330 [==============================] - 6s 19ms/step - loss: 0.0291 - val_loss: 0.1584\n",
            "Epoch 20/20\n",
            "330/330 [==============================] - 7s 21ms/step - loss: 0.0260 - val_loss: 0.1596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "years = list(range(2017, 2020))\n",
        "y_pred = {year: [] for year in years}\n",
        "y_true = {year: [] for year in years}\n",
        "\n",
        "for year in years:\n",
        "    dir = f'/content/drive/MyDrive/encodings/{year}_new_encoded/'\n",
        "    for district in listdir(dir):\n",
        "        if 'ipynb' in district:\n",
        "            continue\n",
        "        name = district[:-4]\n",
        "        data = np.load(dir + district)\n",
        "        n_patches = data.shape[0]\n",
        "        \n",
        "        for i in range(12):\n",
        "            data_temp = data[:, i, :, :]\n",
        "            y_pred[year].append(model.predict(data_temp).mean())\n",
        "        \n",
        "        df_temp = df.loc[name]\n",
        "        mask = (df_temp.index < pd.to_datetime(f'{year+1}-01-01')) & (df_temp.index >= pd.to_datetime(f'{year}-01-01'))\n",
        "        y_true[year] += list(df_temp[mask].to_numpy())\n",
        "\n",
        "    y_true[year] = np.array(y_true[year]).flatten()\n",
        "    y_pred[year] = np.array(y_pred[year]).flatten()"
      ],
      "metadata": {
        "id": "stFTxHrlahDq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for year in [2017, 2018, 2019]:\n",
        "    print(year)\n",
        "    print((((y_true[year] - y_pred[year])**2).mean()**0.5)/y_true[year].std())\n",
        "    print(r2_score(y_true[year], y_pred[year]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q02qVdhvBuPC",
        "outputId": "faa7c684-69c9-4bd3-c84b-b7c84e1c668c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017\n",
            "0.1037986526570091\n",
            "0.9892258397065896\n",
            "2018\n",
            "0.08700947566967512\n",
            "0.9924293511436882\n",
            "2019\n",
            "0.2905634689057278\n",
            "0.9155728705374702\n"
          ]
        }
      ]
    }
  ]
}